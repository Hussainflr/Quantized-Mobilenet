{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ BitOps: The Concept\n",
    "\n",
    "> **BitOps = Number of operations √ó Bit-width per operation**\n",
    "\n",
    "In quantized networks, instead of counting full 32-bit floating point operations (FLOPs), we count operations using lower precision (e.g., 2-bit, 4-bit). So, each multiplication or addition between quantized weights and inputs counts as a **bitwise operation**, scaled by the number of bits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 1. **Depthwise Convolution BitOps**\n",
    "\n",
    "In a **depthwise convolution**, each input channel is convolved separately:\n",
    "\n",
    "### **Formula:**\n",
    "\n",
    "$$\n",
    "\\text{BitOps}_{\\text{depthwise}} = H_{\\text{out}} \\times W_{\\text{out}} \\times C_{\\text{in}} \\times K \\times K \\times B\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $H_{\\text{out}}, W_{\\text{out}}$: height and width of the output feature map  $$\n",
    "- $C_{\\text{in}}$: number of input channels  \n",
    "- $K \\text{x} K$: kernel size (usually \\$3 x 3$)  \n",
    "- $ B$: bit-width used for quantized weights \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 2. **Pointwise Convolution BitOps**\n",
    "\n",
    "A **pointwise convolution** is a \\(1 \\times 1\\) convolution across channels, essentially a matrix multiplication.\n",
    "\n",
    "### **Formula:**\n",
    "\n",
    "$$\n",
    "\\text{BitOps}_{\\text{pointwise}} = H_{\\text{out}} \\times W_{\\text{out}} \\times C_{\\text{in}} \\times C_{\\text{out}} \\times B\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "<br>\n",
    "\n",
    "- $H_{\\text{out}},\\ W_{\\text{out}}$: output size (same as input to pointwise conv)  \n",
    "- $C_{\\text{in}}$: number of input channels  \n",
    "- $C_{\\text{out}}$: number of output channels  \n",
    "- $B$: bit-width used for quantized weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Output Size**:\n",
    "\n",
    "$$\n",
    "H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2P - K}{S} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- \\( P \\): padding  \n",
    "- \\( K \\): kernel size  \n",
    "- \\( S \\): stride  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Example (Depthwise Layer)\n",
    "\n",
    "For a depthwise conv with:  \n",
    "- $Input: 32 x 32, 64 channels$  \n",
    "- $Kernel: 3 x 3$\n",
    "- $Stride: 1$  \n",
    "- $Precision: 4-bit$  \n",
    "\n",
    "$$\n",
    "\\text{BitOps}_{\\text{depthwise}} = 32 \\times 32 \\times 64 \\times 3 \\times 3 \\times 4 = 2,359,296 \\text{ BitOps}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function for weight quantization\n",
    "def quantize_weights(weights, num_bits):\n",
    "    qmin = -2 ** (num_bits - 1)\n",
    "    qmax = 2 ** (num_bits - 1) - 1\n",
    "    scale = weights.abs().max() / qmax\n",
    "    quantized = torch.round(weights / scale).clamp(qmin, qmax) * scale\n",
    "    return quantized\n",
    "\n",
    "# Calculate BitOps for a conv layer\n",
    "def calculate_bitops(conv_layer, input_size, weight_precision):\n",
    "    out_channels = conv_layer.out_channels\n",
    "    in_channels = conv_layer.in_channels\n",
    "    kernel_size = conv_layer.kernel_size[0] * conv_layer.kernel_size[1]\n",
    "    stride = conv_layer.stride[0]\n",
    "    padding = conv_layer.padding[0]\n",
    "\n",
    "    H_in, W_in = input_size\n",
    "    H_out = (H_in + 2 * padding - conv_layer.kernel_size[0]) // stride + 1\n",
    "    W_out = (W_in + 2 * padding - conv_layer.kernel_size[1]) // stride + 1\n",
    "\n",
    "    ops_per_position = in_channels * kernel_size\n",
    "    total_ops = ops_per_position * H_out * W_out * out_channels\n",
    "\n",
    "    return total_ops * weight_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a depthwise separable conv block with quantization\n",
    "class QuantizedMobileNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, weight_precision):\n",
    "        super().__init__()\n",
    "        self.weight_precision = weight_precision\n",
    "        self.stride = stride\n",
    "\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.depthwise.weight.data = quantize_weights(self.depthwise.weight.data, self.weight_precision)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu6(x)\n",
    "\n",
    "        self.pointwise.weight.data = quantize_weights(self.pointwise.weight.data, self.weight_precision)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu6(x)\n",
    "        return x\n",
    "    \n",
    "    def bitops_dict(self, input_size):\n",
    "        dw_bitops = calculate_bitops(self.depthwise, input_size, self.weight_precision)\n",
    "        H_out = (input_size[0] + 2 * self.depthwise.padding[0] - 3) // self.stride + 1\n",
    "        W_out = (input_size[1] + 2 * self.depthwise.padding[0] - 3) // self.stride + 1\n",
    "        pw_bitops = calculate_bitops(self.pointwise, (H_out, W_out), self.weight_precision)\n",
    "\n",
    "        return {\n",
    "            'depthwise': dw_bitops,\n",
    "            'pointwise': pw_bitops,\n",
    "            'total': dw_bitops + pw_bitops,\n",
    "            'output_size': (H_out, W_out)\n",
    "        }\n",
    "\n",
    "    def bitops(self, input_size):\n",
    "        dw_bitops = calculate_bitops(self.depthwise, input_size, self.weight_precision)\n",
    "        H_out = (input_size[0] + 2 * self.depthwise.padding[0] - 3) // self.stride + 1\n",
    "        W_out = (input_size[1] + 2 * self.depthwise.padding[0] - 3) // self.stride + 1\n",
    "        pw_bitops = calculate_bitops(self.pointwise, (H_out, W_out), self.weight_precision)\n",
    "        return dw_bitops + pw_bitops, (H_out, W_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Build the full model\n",
    "class QuantizedMobileNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        input_channels = 3\n",
    "        for out_channels, stride, bits in config:\n",
    "            block = QuantizedMobileNetBlock(input_channels, out_channels, stride, bits)\n",
    "            self.blocks.append(block)\n",
    "            input_channels = out_channels\n",
    "        self.classifier = nn.Linear(input_channels, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# Calculate BitOps for each layer\n",
    "    def bitops_per_layer(self, input_size):\n",
    "        current_size = input_size\n",
    "        all_ops = []\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            ops = block.bitops_dict(current_size)\n",
    "            all_ops.append({\n",
    "                'block': idx,\n",
    "                'depthwise_bitops': ops['depthwise'],\n",
    "                'pointwise_bitops': ops['pointwise'],\n",
    "                'total_block_bitops': ops['total']\n",
    "            })\n",
    "            current_size = ops['output_size']\n",
    "        return all_ops\n",
    "\n",
    "# Calculate total BitOps for the entire model\n",
    "\n",
    "    def total_bitops(self, input_size):\n",
    "        total = 0\n",
    "        current_size = input_size\n",
    "        for block in self.blocks:\n",
    "            ops, current_size = block.bitops(current_size)\n",
    "            total += ops\n",
    "        return total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for CIFAR-10\n",
    "def train(model, train_loader, val_loader, device, epochs=10):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_accs.append(correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                correct += (outputs.argmax(1) == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        val_losses.append(total_loss / len(val_loader))\n",
    "        val_accs.append(correct / total)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accs,\n",
    "        'val_acc': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "Total BitOps: 8.38e+07\n",
      "Block 0 -> Depthwise: 6.64e+05, Pointwise: 7.86e+05, Total: 1.45e+06\n",
      "Block 1 -> Depthwise: 9.44e+06, Pointwise: 2.10e+06, Total: 1.15e+07\n",
      "Block 2 -> Depthwise: 4.72e+06, Pointwise: 1.05e+06, Total: 5.77e+06\n",
      "Block 3 -> Depthwise: 3.77e+07, Pointwise: 4.19e+06, Total: 4.19e+07\n",
      "Block 4 -> Depthwise: 1.89e+07, Pointwise: 4.19e+06, Total: 2.31e+07\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    mobilenet_config = [\n",
    "        (32, 1, 8),\n",
    "        (64, 2, 4),\n",
    "        (128, 2, 2),\n",
    "        (128, 1, 4),\n",
    "        (256, 2, 8),\n",
    "    ]\n",
    "\n",
    "    model = QuantizedMobileNet(mobilenet_config)\n",
    "    dummy_input = torch.randn(1, 3, 32, 32)\n",
    "    output = model(dummy_input)\n",
    "    print(output.shape)  \n",
    "\n",
    "    total_bitops = model.total_bitops((32, 32))\n",
    "    print(f\"Total BitOps: {total_bitops:.2e}\")\n",
    "    layer_ops = model.bitops_per_layer((32, 32))\n",
    "    for op in layer_ops:\n",
    "        print(f\"Block {op['block']} -> Depthwise: {op['depthwise_bitops']:.2e}, \"\n",
    "              f\"Pointwise: {op['pointwise_bitops']:.2e}, \"\n",
    "              f\"Total: {op['total_block_bitops']:.2e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     mobilenet_config = [\n",
    "#         (32, 1, 8),\n",
    "#         (64, 2, 4),\n",
    "#         (128, 2, 2),\n",
    "#         (128, 1, 4),\n",
    "#         (256, 2, 8),\n",
    "#     ]\n",
    "\n",
    "#     model = QuantizedMobileNet(mobilenet_config)\n",
    "\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     ])\n",
    "\n",
    "#     train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#     val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     log = train(model, train_loader, val_loader, device, epochs=1)\n",
    "\n",
    "#     total_bitops = model.total_bitops((32, 32))\n",
    "#     print(f\"Total BitOps: {total_bitops:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "Total BitOps: 4.10e+09\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    mobilenet_config = [\n",
    "        (32, 1, 8),\n",
    "        (64, 2, 4),\n",
    "        (128, 2, 2),\n",
    "        (128, 1, 4),\n",
    "        (256, 2, 8),\n",
    "    ]\n",
    "\n",
    "    model = QuantizedMobileNet(mobilenet_config)\n",
    "    dummy_input = torch.randn(1, 3, 224, 224)\n",
    "    output = model(dummy_input)\n",
    "    print(output.shape)  \n",
    "\n",
    "    total_bitops = model.total_bitops((224, 224))\n",
    "    print(f\"Total BitOps: {total_bitops:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
